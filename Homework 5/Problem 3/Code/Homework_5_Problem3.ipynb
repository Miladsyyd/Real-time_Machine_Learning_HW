{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import math\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Embedded English-to-French dataset\n",
        "data = [\n",
        "   (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
        "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
        "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
        "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
        "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
        "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
        "    (\"They go shopping\", \"Ils font du shopping\"),\n",
        "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
        "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
        "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
        "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
        "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
        "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
        "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
        "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
        "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
        "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
        "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
        "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
        "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
        "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
        "    (\"They set the table\", \"Ils mettent la table\"),\n",
        "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
        "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
        "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
        "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
        "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
        "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
        "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
        "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
        "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
        "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
        "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
        "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
        "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
        "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
        "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
        "]\n",
        "\n",
        "# Tokenizer & Vocab\n",
        "def tokenize(text):\n",
        "    return text.lower().strip().split()\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, texts, specials=[\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"]):\n",
        "        tokens = [tok for sent in texts for tok in tokenize(sent)]\n",
        "        self.itos = specials + sorted(set(tokens))\n",
        "        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n",
        "        self.pad = self.stoi[\"<pad>\"]\n",
        "        self.bos = self.stoi[\"<bos>\"]\n",
        "        self.eos = self.stoi[\"<eos>\"]\n",
        "        self.unk = self.stoi[\"<unk>\"]\n",
        "\n",
        "    def encode(self, text):\n",
        "        return [self.bos] + [self.stoi.get(tok, self.unk) for tok in tokenize(text)] + [self.eos]\n",
        "\n",
        "    def decode(self, ids):\n",
        "        return \" \".join([self.itos[i] for i in ids if i not in [self.bos, self.eos, self.pad]])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "en_vocab = Vocab([en for en, fr in data])\n",
        "fr_vocab = Vocab([fr for en, fr in data])\n",
        "\n",
        "# Dataset & Collate Function\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        en, fr = self.pairs[idx]\n",
        "        return torch.tensor(en_vocab.encode(en)), torch.tensor(fr_vocab.encode(fr))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src, tgt = zip(*batch)\n",
        "    src = pad_sequence(src, batch_first=True, padding_value=en_vocab.pad)\n",
        "    tgt = pad_sequence(tgt, batch_first=True, padding_value=fr_vocab.pad)\n",
        "    return src.to(device), tgt.to(device)\n",
        "\n",
        "dataset = TranslationDataset(data)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaczvKlu5hzs",
        "outputId": "073acf95-59d1-4768-ea8b-8e7ac085998f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Positional Encoding for Transformer\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size, max_len=5000):\n",
        "        super().__init__()\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, emb_size, 2) * (-math.log(10000.0) / emb_size))\n",
        "        pe = torch.zeros(max_len, emb_size)\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.pe = pe.unsqueeze(0).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n"
      ],
      "metadata": {
        "id": "1GkwMnlf51bG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Transformer Encoder-Decoder\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, en_vocab_size, fr_vocab_size, emb_size=128, num_heads=2, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.src_emb = nn.Embedding(en_vocab_size, emb_size)\n",
        "        self.tgt_emb = nn.Embedding(fr_vocab_size, emb_size)\n",
        "        self.pos_enc = PositionalEncoding(emb_size)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=emb_size,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=512,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(emb_size, fr_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = self.transformer.generate_square_subsequent_mask(src.size(1)).to(device)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
        "        src = self.pos_enc(self.src_emb(src))\n",
        "        tgt = self.pos_enc(self.tgt_emb(tgt))\n",
        "        out = self.transformer(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "Mv0Fmwbk55Lr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Training Loop with Accuracy\n",
        "def train_seq2seq(model, train_loader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=fr_vocab.pad)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for src, tgt in train_loader:\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_expected = tgt[:, 1:]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "            tgt_expected = tgt_expected.reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt_expected)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (output.argmax(1) == tgt_expected).sum().item()\n",
        "            total += tgt_expected.ne(fr_vocab.pad).sum().item()\n",
        "\n",
        "        acc = correct / total\n",
        "        print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "TOKgR-Lm57DW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Translate Function\n",
        "def translate(model, sentence, max_len=20):\n",
        "    model.eval()\n",
        "    src = torch.tensor(en_vocab.encode(sentence)).unsqueeze(0).to(device)\n",
        "    tgt = torch.tensor([[fr_vocab.bos]]).to(device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out = model(src, tgt)\n",
        "            next_token = out[:, -1, :].argmax(dim=1, keepdim=True)\n",
        "            tgt = torch.cat([tgt, next_token], dim=1)\n",
        "            if next_token.item() == fr_vocab.eos:\n",
        "                break\n",
        "\n",
        "    return fr_vocab.decode(tgt[0].tolist())\n"
      ],
      "metadata": {
        "id": "c31SXwOj58dF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Example (Transformer, 2 layers, 2 heads)\n",
        "model = TransformerModel(len(en_vocab), len(fr_vocab), emb_size=128, num_heads=2, num_layers=2)\n",
        "train_seq2seq(model, train_loader, epochs=10)\n",
        "\n",
        "print(\"\\nSample Translations:\")\n",
        "print(\"EN: She is happy\\nFR:\", translate(model, \"She is happy\"))\n",
        "print(\"EN: We are friends\\nFR:\", translate(model, \"We are friends\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCa1p2L66AlX",
        "outputId": "5ac79794-2dc1-4755-9cb9-7d775aee8545"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 276.6891 | Accuracy: 0.1782\n",
            "Epoch 2 | Loss: 237.9561 | Accuracy: 0.2565\n",
            "Epoch 3 | Loss: 209.2220 | Accuracy: 0.3257\n",
            "Epoch 4 | Loss: 185.0777 | Accuracy: 0.3579\n",
            "Epoch 5 | Loss: 164.8015 | Accuracy: 0.3840\n",
            "Epoch 6 | Loss: 142.3807 | Accuracy: 0.4409\n",
            "Epoch 7 | Loss: 122.8505 | Accuracy: 0.4977\n",
            "Epoch 8 | Loss: 108.0628 | Accuracy: 0.5453\n",
            "Epoch 9 | Loss: 93.5866 | Accuracy: 0.6206\n",
            "Epoch 10 | Loss: 81.2859 | Accuracy: 0.6498\n",
            "\n",
            "Sample Translations:\n",
            "EN: She is happy\n",
            "FR: elle étudie dur pour les examens\n",
            "EN: We are friends\n",
            "FR: nous pratiquons le yoga\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Configs + Report Results\n",
        "def run_transformer_configs():\n",
        "    results = []\n",
        "    configs = [(l, h) for l in [1, 2, 4] for h in [2, 4]]\n",
        "\n",
        "    for num_layers, num_heads in configs:\n",
        "        print(f\"\\n===== Layers: {num_layers}, Heads: {num_heads} =====\")\n",
        "        model = TransformerModel(\n",
        "            en_vocab_size=len(en_vocab),\n",
        "            fr_vocab_size=len(fr_vocab),\n",
        "            emb_size=128,\n",
        "            num_heads=num_heads,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        start = time.time()\n",
        "        train_seq2seq(model, train_loader, epochs=5)\n",
        "        duration = time.time() - start\n",
        "\n",
        "        # Sample translation (qualitative)\n",
        "        sample_translation = translate(model, \"We are friends\")\n",
        "\n",
        "        # Save result for the report\n",
        "        results.append({\n",
        "            \"layers\": num_layers,\n",
        "            \"heads\": num_heads,\n",
        "            \"params\": sum(p.numel() for p in model.parameters()),\n",
        "            \"time\": round(duration, 2),\n",
        "            \"sample\": sample_translation\n",
        "        })\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "ooSOKBeF6R4-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##Results\n",
        "transformer_results = run_transformer_configs()\n",
        "\n",
        "print(\"\\n=== Summary of All Transformer Configs ===\")\n",
        "for res in transformer_results:\n",
        "    print(f\"Layers: {res['layers']} | Heads: {res['heads']} | Params: {res['params']:,} | Time: {res['time']}s\")\n",
        "    print(\"Example Translation (EN → FR):\", res[\"sample\"])\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P5Lu0OL6T78",
        "outputId": "24f0f43f-654c-4ac2-9ba0-2624ebe910d1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Layers: 1, Heads: 2 =====\n",
            "Epoch 1 | Loss: 269.2060 | Accuracy: 0.2012\n",
            "Epoch 2 | Loss: 212.2786 | Accuracy: 0.3425\n",
            "Epoch 3 | Loss: 174.2274 | Accuracy: 0.3948\n",
            "Epoch 4 | Loss: 142.2813 | Accuracy: 0.4501\n",
            "Epoch 5 | Loss: 116.3273 | Accuracy: 0.5515\n",
            "\n",
            "===== Layers: 1, Heads: 4 =====\n",
            "Epoch 1 | Loss: 274.5360 | Accuracy: 0.1920\n",
            "Epoch 2 | Loss: 215.2379 | Accuracy: 0.3441\n",
            "Epoch 3 | Loss: 176.6418 | Accuracy: 0.3886\n",
            "Epoch 4 | Loss: 140.4070 | Accuracy: 0.4716\n",
            "Epoch 5 | Loss: 109.7357 | Accuracy: 0.5991\n",
            "\n",
            "===== Layers: 2, Heads: 2 =====\n",
            "Epoch 1 | Loss: 282.5960 | Accuracy: 0.1705\n",
            "Epoch 2 | Loss: 243.6773 | Accuracy: 0.2765\n",
            "Epoch 3 | Loss: 216.6537 | Accuracy: 0.3333\n",
            "Epoch 4 | Loss: 188.9188 | Accuracy: 0.3717\n",
            "Epoch 5 | Loss: 169.3456 | Accuracy: 0.3840\n",
            "\n",
            "===== Layers: 2, Heads: 4 =====\n",
            "Epoch 1 | Loss: 278.8982 | Accuracy: 0.1813\n",
            "Epoch 2 | Loss: 239.7712 | Accuracy: 0.2488\n",
            "Epoch 3 | Loss: 214.0940 | Accuracy: 0.3226\n",
            "Epoch 4 | Loss: 186.5194 | Accuracy: 0.3687\n",
            "Epoch 5 | Loss: 163.8985 | Accuracy: 0.3871\n",
            "\n",
            "===== Layers: 4, Heads: 2 =====\n",
            "Epoch 1 | Loss: 285.7115 | Accuracy: 0.1690\n",
            "Epoch 2 | Loss: 265.1832 | Accuracy: 0.1905\n",
            "Epoch 3 | Loss: 257.7800 | Accuracy: 0.1966\n",
            "Epoch 4 | Loss: 250.5067 | Accuracy: 0.1966\n",
            "Epoch 5 | Loss: 246.7785 | Accuracy: 0.1920\n",
            "\n",
            "===== Layers: 4, Heads: 4 =====\n",
            "Epoch 1 | Loss: 285.4999 | Accuracy: 0.1674\n",
            "Epoch 2 | Loss: 260.3483 | Accuracy: 0.2028\n",
            "Epoch 3 | Loss: 250.5438 | Accuracy: 0.2135\n",
            "Epoch 4 | Loss: 247.5036 | Accuracy: 0.1997\n",
            "Epoch 5 | Loss: 246.2218 | Accuracy: 0.1982\n",
            "\n",
            "=== Summary of All Transformer Configs ===\n",
            "Layers: 1 | Heads: 2 | Params: 566,035 | Time: 2.5s\n",
            "Example Translation (EN → FR): nous regardons un château\n",
            "------------------------------------------------------------\n",
            "Layers: 1 | Heads: 4 | Params: 566,035 | Time: 2.55s\n",
            "Example Translation (EN → FR): nous sommes amis\n",
            "------------------------------------------------------------\n",
            "Layers: 2 | Heads: 2 | Params: 1,028,883 | Time: 4.17s\n",
            "Example Translation (EN → FR): nous cuisinons le jardin le nous cuisinons\n",
            "------------------------------------------------------------\n",
            "Layers: 2 | Heads: 4 | Params: 1,028,883 | Time: 4.11s\n",
            "Example Translation (EN → FR): nous regardons des\n",
            "------------------------------------------------------------\n",
            "Layers: 4 | Heads: 2 | Params: 1,954,579 | Time: 7.67s\n",
            "Example Translation (EN → FR): il il il il il il il il il il il il il il il il il il il il\n",
            "------------------------------------------------------------\n",
            "Layers: 4 | Heads: 4 | Params: 1,954,579 | Time: 7.6s\n",
            "Example Translation (EN → FR): elle\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############RNN Encoder-Decoder (No Attention)\n",
        "class RNNEncoder(nn.Module):\n",
        "    def __init__(self, input_size, emb_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_size, emb_size)\n",
        "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        outputs, hidden = self.rnn(emb)\n",
        "        return outputs, hidden\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, output_size, emb_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_size, emb_size)\n",
        "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embedding(x)\n",
        "        out, hidden = self.rnn(emb, hidden)\n",
        "        return self.fc(out), hidden\n",
        "\n",
        "class Seq2SeqRNN(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        _, hidden = self.encoder(src)\n",
        "        output, _ = self.decoder(tgt, hidden)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "8y5tty9y7Hz3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Train RNN Model\n",
        "\n",
        "def train_rnn(model, loader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=fr_vocab.pad)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for src, tgt in loader:\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_expected = tgt[:, 1:]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "            tgt_expected = tgt_expected.reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt_expected)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (output.argmax(1) == tgt_expected).sum().item()\n",
        "            total += tgt_expected.ne(fr_vocab.pad).sum().item()\n",
        "\n",
        "        acc = correct / total\n",
        "        print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "v6tWofi57OiG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####Translate with RNN (No Attention)\n",
        "\n",
        "def translate_rnn(model, sentence, max_len=20):\n",
        "    model.eval()\n",
        "    src = torch.tensor(en_vocab.encode(sentence)).unsqueeze(0).to(device)\n",
        "    tgt = torch.tensor([[fr_vocab.bos]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, hidden = model.encoder(src)\n",
        "        for _ in range(max_len):\n",
        "            out, hidden = model.decoder(tgt[:, -1:], hidden)\n",
        "            next_token = out[:, -1, :].argmax(1, keepdim=True)\n",
        "            tgt = torch.cat([tgt, next_token], dim=1)\n",
        "            if next_token.item() == fr_vocab.eos:\n",
        "                break\n",
        "\n",
        "    return fr_vocab.decode(tgt[0].tolist())\n"
      ],
      "metadata": {
        "id": "eJxBWGey7QF-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####RNN Model (No Attention)\n",
        "\n",
        "emb_size = 128\n",
        "hidden_size = 256\n",
        "\n",
        "rnn_enc = RNNEncoder(len(en_vocab), emb_size, hidden_size)\n",
        "rnn_dec = RNNDecoder(len(fr_vocab), emb_size, hidden_size)\n",
        "rnn_model = Seq2SeqRNN(rnn_enc, rnn_dec)\n",
        "\n",
        "train_rnn(rnn_model, train_loader, epochs=10)\n",
        "\n",
        "print(\"\\nSample RNN Translations:\")\n",
        "print(\"EN: She is happy\\nFR:\", translate_rnn(rnn_model, \"She is happy\"))\n",
        "print(\"EN: We are friends\\nFR:\", translate_rnn(rnn_model, \"We are friends\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpIC_gLD7cU2",
        "outputId": "d781f2ef-6283-45d7-b517-ce731e91e8d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 274.7988 | Accuracy: 0.1751\n",
            "Epoch 2 | Loss: 210.1739 | Accuracy: 0.2857\n",
            "Epoch 3 | Loss: 163.8053 | Accuracy: 0.3932\n",
            "Epoch 4 | Loss: 127.9829 | Accuracy: 0.4654\n",
            "Epoch 5 | Loss: 96.6808 | Accuracy: 0.5760\n",
            "Epoch 6 | Loss: 71.7439 | Accuracy: 0.6974\n",
            "Epoch 7 | Loss: 53.4090 | Accuracy: 0.7865\n",
            "Epoch 8 | Loss: 39.4856 | Accuracy: 0.8464\n",
            "Epoch 9 | Loss: 30.2204 | Accuracy: 0.8955\n",
            "Epoch 10 | Loss: 22.5560 | Accuracy: 0.9386\n",
            "\n",
            "Sample RNN Translations:\n",
            "EN: She is happy\n",
            "FR: elle est heureuse\n",
            "EN: We are friends\n",
            "FR: nous sommes amis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Attention Module\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [batch, 1, hidden]\n",
        "        # encoder_outputs: [batch, seq_len, hidden]\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "\n",
        "        hidden = hidden.repeat(1, seq_len, 1)  # [batch, seq_len, hidden]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch, seq_len, hidden]\n",
        "        energy = energy.transpose(1, 2)  # [batch, hidden, seq_len]\n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)  # [batch, 1, hidden]\n",
        "        attn_weights = torch.bmm(v, energy).squeeze(1)  # [batch, seq_len]\n",
        "        return torch.softmax(attn_weights, dim=1)  # [batch, seq_len]\n"
      ],
      "metadata": {
        "id": "hfcf-wqP78VG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Decoder with Attention\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, output_size, emb_size, hidden_size, attention):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_size, emb_size)\n",
        "        self.rnn = nn.GRU(hidden_size + emb_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
        "        self.attention = attention\n",
        "\n",
        "    def forward(self, x, hidden, encoder_outputs):\n",
        "        # x: [batch, 1]\n",
        "        embedded = self.embedding(x)  # [batch, 1, emb]\n",
        "        attn_weights = self.attention(hidden.permute(1, 0, 2), encoder_outputs)  # [batch, seq_len]\n",
        "        attn_weights = attn_weights.unsqueeze(1)  # [batch, 1, seq_len]\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)  # [batch, 1, hidden]\n",
        "\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)  # [batch, 1, hidden + emb]\n",
        "        output, hidden = self.rnn(rnn_input, hidden)  # output: [batch, 1, hidden]\n",
        "        output = self.fc(torch.cat((output, context), dim=2))  # [batch, 1, output_size]\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "eFM49-9J8A6n"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Seq2Seq with Attention\n",
        "class Seq2SeqAttn(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(tgt.size(1)):\n",
        "            out, hidden = self.decoder(tgt[:, t].unsqueeze(1), hidden, encoder_outputs)\n",
        "            outputs.append(out)\n",
        "\n",
        "        return torch.cat(outputs, dim=1)\n"
      ],
      "metadata": {
        "id": "flNAtWc78El-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Train Attention-Based RNN\n",
        "def train_rnn_attention(model, loader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=fr_vocab.pad)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for src, tgt in loader:\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_expected = tgt[:, 1:]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)  # output: [batch, seq_len, vocab]\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "            tgt_expected = tgt_expected.reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt_expected)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (output.argmax(1) == tgt_expected).sum().item()\n",
        "            total += tgt_expected.ne(fr_vocab.pad).sum().item()\n",
        "\n",
        "        acc = correct / total\n",
        "        print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "V5UdDojt8Jlf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Translate with RNN + Attention\n",
        "def translate_rnn_attention(model, sentence, max_len=20):\n",
        "    model.eval()\n",
        "    src = torch.tensor(en_vocab.encode(sentence)).unsqueeze(0).to(device)\n",
        "    tgt = torch.tensor([[fr_vocab.bos]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src)\n",
        "        for _ in range(max_len):\n",
        "            out, hidden = model.decoder(tgt[:, -1:], hidden, encoder_outputs)\n",
        "            next_token = out[:, -1, :].argmax(1, keepdim=True)\n",
        "            tgt = torch.cat([tgt, next_token], dim=1)\n",
        "            if next_token.item() == fr_vocab.eos:\n",
        "                break\n",
        "\n",
        "    return fr_vocab.decode(tgt[0].tolist())\n"
      ],
      "metadata": {
        "id": "ym8JFgMi8Qn2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Attention-Based RNN\n",
        "emb_size = 128\n",
        "hidden_size = 256\n",
        "\n",
        "attn = Attention(hidden_size)\n",
        "rnn_enc_attn = RNNEncoder(len(en_vocab), emb_size, hidden_size)\n",
        "rnn_dec_attn = AttnDecoder(len(fr_vocab), emb_size, hidden_size, attn)\n",
        "rnn_attn_model = Seq2SeqAttn(rnn_enc_attn, rnn_dec_attn)\n",
        "\n",
        "train_rnn_attention(rnn_attn_model, train_loader, epochs=10)\n",
        "\n",
        "print(\"\\nSample RNN + Attention Translations:\")\n",
        "print(\"EN: She is happy\\nFR:\", translate_rnn_attention(rnn_attn_model, \"She is happy\"))\n",
        "print(\"EN: We are friends\\nFR:\", translate_rnn_attention(rnn_attn_model, \"We are friends\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFJxhGLL8WGL",
        "outputId": "798c95ec-6f98-4209-ae92-a0c5efaa0f20"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 264.1111 | Accuracy: 0.2227\n",
            "Epoch 2 | Loss: 208.9293 | Accuracy: 0.2842\n",
            "Epoch 3 | Loss: 168.0370 | Accuracy: 0.3779\n",
            "Epoch 4 | Loss: 130.7345 | Accuracy: 0.4547\n",
            "Epoch 5 | Loss: 101.0747 | Accuracy: 0.5407\n",
            "Epoch 6 | Loss: 77.6414 | Accuracy: 0.6590\n",
            "Epoch 7 | Loss: 58.9012 | Accuracy: 0.7343\n",
            "Epoch 8 | Loss: 46.3664 | Accuracy: 0.7926\n",
            "Epoch 9 | Loss: 37.7987 | Accuracy: 0.8187\n",
            "Epoch 10 | Loss: 30.2842 | Accuracy: 0.8602\n",
            "\n",
            "Sample RNN + Attention Translations:\n",
            "EN: She is happy\n",
            "FR: elle est heureuse\n",
            "EN: We are friends\n",
            "FR: nous sommes amis\n"
          ]
        }
      ]
    }
  ]
}