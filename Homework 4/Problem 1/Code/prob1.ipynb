{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oYGGtYmPcPk",
        "outputId": "ce8df497-1bc9-4fe8-8d75-11ac6102b339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French tokenizer word_index: {'<sos>': 1, '<eos>': 2, 'le': 3, 'la': 4, 'il': 5, 'elle': 6, 'nous': 7, 'ils': 8, 'les': 9, 'de': 10, 'à': 11, 'des': 12, 'au': 13, 'dans': 14, 'du': 15, 'une': 16, 'un': 17, 'se': 18, 'font': 19, 'est': 20, 'chat': 21, 'dort': 22, 'soleil': 23, 'musique': 24, 'jouent': 25, 'porte': 26, 'ensemble': 27, 'étudie': 28, 'bruyamment': 29, 'chante': 30, 'matin': 31, 'pour': 32, 'brille': 33, 'livres': 34, 'chaque': 35, 'film': 36, 'dîner': 37, 'voiture': 38, 'visitent': 39, 'cuisine': 40, 'regardons': 41, 'en': 42, 'voyagent': 43, 'table': 44, 'danse': 45, 'avec': 46, 'dur': 47, 'fleurs': 48, 'écrit': 49, 'son': 50, 'peint': 51, 'parc': 52, 'train': 53, 'bébé': 54, 'répare': 55, 'café': 56, 'doucement': 57, 'bus': 58, 'vélo': 59, 'nos': 60, 'ses': 61, \"j'ai\": 62, 'froid': 63, 'tu': 64, 'es': 65, 'fatigué': 66, 'a': 67, 'faim': 68, 'heureuse': 69, 'sommes': 70, 'amis': 71, 'sont': 72, 'étudiants': 73, 'aimons': 74, 'parle': 75, 'français': 76, 'couramment': 77, 'aime': 78, 'lire': 79, 'football': 80, 'week-end': 81, 'commence': 82, '19': 83, 'heures': 84, 'robe': 85, 'rouge': 86, 'cuisinons': 87, 'conduit': 88, 'bleue': 89, 'souvent': 90, 'musées': 91, 'restaurant': 92, 'sert': 93, 'délicieuse': 94, 'mathématiques': 95, \"l'université\": 96, 'films': 97, 'vendredi': 98, 'écoute': 99, 'faisant': 100, 'jogging': 101, 'autour': 102, 'monde': 103, 'livre': 104, 'sur': 105, 'grâce': 106, 'célébrons': 107, 'anniversaires': 108, 'gâteau': 109, 'travaille': 110, 'tous': 111, 'jours': 112, 'parlent': 113, 'différentes': 114, 'langues': 115, 'fleurissent': 116, 'printemps': 117, 'poésie': 118, 'pendant': 119, 'temps': 120, 'libre': 121, 'apprenons': 122, 'quelque': 123, 'chose': 124, 'nouveau': 125, 'jour': 126, 'chien': 127, 'aboie': 128, 'magnifiquement': 129, 'nagent': 130, 'piscine': 131, 'oiseaux': 132, 'gazouillent': 133, 'enseigne': 134, \"l'anglais\": 135, \"l'école\": 136, 'prenons': 137, 'petit': 138, 'déjeuner': 139, 'paysages': 140, 'rient': 141, 'blague': 142, \"l'horloge\": 143, 'tic-tac': 144, 'court': 145, 'voyageons': 146, 'lettre': 147, 'lisent': 148, 'bibliothèque': 149, 'pleure': 150, 'examens': 151, 'plantons': 152, 'jardin': 153, 'boivent': 154, 'couche': 155, 'soir': 156, 'fête': 157, 'jouons': 158, 'concert': 159, 'sa': 160, 'famille': 161, 'étudient': 162, 'grammaire': 163, 'française': 164, 'pluie': 165, 'tombe': 166, 'chanson': 167, 'profondément': 168, 'paris': 169, 'enfants': 170, 'promène': 171, 'long': 172, 'plage': 173, 'parlons': 174, 'téléphone': 175, 'attend': 176, 'tour': 177, 'eiffel': 178, 'étoiles': 179, 'scintillent': 180, 'nuit': 181, 'rêve': 182, 'voler': 183, 'travaillons': 184, 'bureau': 185, \"l'histoire\": 186, 'écoutent': 187, 'radio': 188, 'vent': 189, 'souffle': 190, 'nage': 191, \"l'océan\": 192, 'dansons': 193, 'mariage': 194, 'gravit': 195, 'montagne': 196, 'randonnée': 197, 'forêt': 198, 'miaule': 199, 'tableau': 200, 'construisons': 201, 'château': 202, 'sable': 203, 'chœur': 204, 'chaud': 205, 'lunettes': 206, 'rendons': 207, 'visite': 208, 'grands-parents': 209, 'joue': 210, 'guitare': 211, 'shopping': 212, 'professeur': 213, 'explique': 214, 'leçon': 215, 'prend': 216, 'aller': 217, 'travail': 218, 'faisons': 219, 'biscuits': 220, 'lave': 221, 'mains': 222, 'apprécient': 223, 'coucher': 224, 'rivière': 225, 'coule': 226, 'calmement': 227, 'nourrit': 228, 'visitons': 229, 'musée': 230, 'peignent': 231, 'murs': 232, 'paisiblement': 233, 'attache': 234, 'lacets': 235, 'montons': 236, 'escaliers': 237, 'rase': 238, 'mettent': 239, \"l'avion\": 240, 'décolle': 241, 'arrose': 242, 'plantes': 243, 'pratiquons': 244, 'yoga': 245, 'éteint': 246, 'lumière': 247, 'aux': 248, 'jeux': 249, 'vidéo': 250, 'soupe': 251, 'sent': 252, 'délicieusement': 253, 'bon': 254, 'ferme': 255, 'clé': 256, 'profitons': 257, \"d'un\": 258, 'pique-nique': 259, 'vérifie': 260, 'emails': 261, 'vont': 262, 'salle': 263, 'sport': 264, 'lune': 265, 'intensément': 266, 'attrape': 267, 'saluons': 268, 'voisins': 269, 'peigne': 270, 'cheveux': 271, 'signe': 272, \"d'adieu\": 273, '<SOS>': 274, '<EOS>': 275}\n",
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.2281 - loss: 5.5254 - val_accuracy: 0.4442 - val_loss: 4.9611\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 940ms/step - accuracy: 0.4243 - loss: 4.5223 - val_accuracy: 0.4239 - val_loss: 4.0624\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.4278 - loss: 3.6275 - val_accuracy: 0.4434 - val_loss: 3.1751\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 960ms/step - accuracy: 0.4458 - loss: 3.1767 - val_accuracy: 0.4434 - val_loss: 3.0692\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 950ms/step - accuracy: 0.4388 - loss: 3.0258 - val_accuracy: 0.4460 - val_loss: 2.7495\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.4830 - loss: 2.6691 - val_accuracy: 0.5416 - val_loss: 2.6929\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 803ms/step - accuracy: 0.5339 - loss: 2.7221 - val_accuracy: 0.5451 - val_loss: 2.5479\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 937ms/step - accuracy: 0.5442 - loss: 2.5255 - val_accuracy: 0.5460 - val_loss: 2.5025\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5513 - loss: 2.4581 - val_accuracy: 0.5496 - val_loss: 2.4511\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 952ms/step - accuracy: 0.5489 - loss: 2.4451 - val_accuracy: 0.5451 - val_loss: 2.3723\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 958ms/step - accuracy: 0.5595 - loss: 2.3040 - val_accuracy: 0.5434 - val_loss: 2.3159\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5443 - loss: 2.2927 - val_accuracy: 0.5549 - val_loss: 2.2659\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 949ms/step - accuracy: 0.5559 - loss: 2.2551 - val_accuracy: 0.5522 - val_loss: 2.2166\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 967ms/step - accuracy: 0.5569 - loss: 2.1811 - val_accuracy: 0.5575 - val_loss: 2.1674\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 904ms/step - accuracy: 0.5603 - loss: 2.1398 - val_accuracy: 0.5602 - val_loss: 2.1246\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 943ms/step - accuracy: 0.5511 - loss: 2.1279 - val_accuracy: 0.5549 - val_loss: 2.0800\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 952ms/step - accuracy: 0.5520 - loss: 2.1055 - val_accuracy: 0.5699 - val_loss: 2.0399\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5653 - loss: 2.0845 - val_accuracy: 0.5814 - val_loss: 2.0019\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 962ms/step - accuracy: 0.5824 - loss: 1.9869 - val_accuracy: 0.5779 - val_loss: 1.9545\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 956ms/step - accuracy: 0.5860 - loss: 1.9225 - val_accuracy: 0.5867 - val_loss: 1.9096\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 915ms/step - accuracy: 0.5920 - loss: 1.9030 - val_accuracy: 0.5965 - val_loss: 1.8685\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 962ms/step - accuracy: 0.5924 - loss: 1.8309 - val_accuracy: 0.5991 - val_loss: 1.8433\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5925 - loss: 1.8688 - val_accuracy: 0.5956 - val_loss: 1.7660\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 953ms/step - accuracy: 0.5902 - loss: 1.7944 - val_accuracy: 0.5947 - val_loss: 1.7433\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 957ms/step - accuracy: 0.6060 - loss: 1.7073 - val_accuracy: 0.6053 - val_loss: 1.6759\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 944ms/step - accuracy: 0.5969 - loss: 1.6956 - val_accuracy: 0.6115 - val_loss: 1.6103\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 968ms/step - accuracy: 0.6084 - loss: 1.6321 - val_accuracy: 0.6106 - val_loss: 1.5575\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 952ms/step - accuracy: 0.6051 - loss: 1.5580 - val_accuracy: 0.6381 - val_loss: 1.4978\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 951ms/step - accuracy: 0.6493 - loss: 1.4711 - val_accuracy: 0.6319 - val_loss: 1.4344\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 951ms/step - accuracy: 0.6325 - loss: 1.4266 - val_accuracy: 0.6531 - val_loss: 1.3727\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.6473 - loss: 1.3989 - val_accuracy: 0.6593 - val_loss: 1.3067\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 953ms/step - accuracy: 0.6635 - loss: 1.2979 - val_accuracy: 0.6832 - val_loss: 1.2438\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 959ms/step - accuracy: 0.6740 - loss: 1.2531 - val_accuracy: 0.6770 - val_loss: 1.1817\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6774 - loss: 1.1884 - val_accuracy: 0.7088 - val_loss: 1.1196\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 824ms/step - accuracy: 0.7030 - loss: 1.1172 - val_accuracy: 0.7177 - val_loss: 1.0572\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 953ms/step - accuracy: 0.7262 - loss: 1.0714 - val_accuracy: 0.7363 - val_loss: 1.0007\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7324 - loss: 0.9838 - val_accuracy: 0.7549 - val_loss: 0.9404\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.7511 - loss: 0.9244 - val_accuracy: 0.7726 - val_loss: 0.8832\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7753 - loss: 0.8845 - val_accuracy: 0.7965 - val_loss: 0.8260\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 952ms/step - accuracy: 0.8000 - loss: 0.8036 - val_accuracy: 0.8106 - val_loss: 0.7764\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 964ms/step - accuracy: 0.8014 - loss: 0.7812 - val_accuracy: 0.8248 - val_loss: 0.7283\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 958ms/step - accuracy: 0.8167 - loss: 0.7357 - val_accuracy: 0.8469 - val_loss: 0.6862\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 954ms/step - accuracy: 0.8335 - loss: 0.6882 - val_accuracy: 0.8602 - val_loss: 0.6290\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.8549 - loss: 0.6319 - val_accuracy: 0.8646 - val_loss: 0.5977\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 822ms/step - accuracy: 0.8597 - loss: 0.5953 - val_accuracy: 0.8761 - val_loss: 0.5518\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 950ms/step - accuracy: 0.8740 - loss: 0.5532 - val_accuracy: 0.8885 - val_loss: 0.5163\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 952ms/step - accuracy: 0.8871 - loss: 0.5156 - val_accuracy: 0.8903 - val_loss: 0.4794\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8927 - loss: 0.4753 - val_accuracy: 0.8956 - val_loss: 0.4510\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 799ms/step - accuracy: 0.8956 - loss: 0.4524 - val_accuracy: 0.9035 - val_loss: 0.4223\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 956ms/step - accuracy: 0.8965 - loss: 0.4286 - val_accuracy: 0.9088 - val_loss: 0.3986\n",
            "Training Loss: 0.4235527515411377\n",
            "Validation Loss (Entire Dataset): 0.3986164629459381\n",
            "Validation Accuracy (Entire Dataset): 0.9088495373725891\n",
            "\n",
            "Qualitative Validation:\n",
            "English: I am cold -> French: tu es des vidéo <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: She is happy -> French: elle dort la <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: We love music -> French: nous font des <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: He drives a blue car -> French: il se une vélo <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: The sun is shining -> French: ils font des <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Ensure eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Dataset (full list as before, truncated here)\n",
        "english_to_french = [\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
        "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
        "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
        "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
        "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
        "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
        "    (\"They go shopping\", \"Ils font du shopping\"),\n",
        "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
        "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
        "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
        "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
        "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
        "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
        "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
        "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
        "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
        "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
        "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
        "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
        "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
        "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
        "    (\"They set the table\", \"Ils mettent la table\"),\n",
        "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
        "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
        "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
        "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
        "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
        "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
        "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
        "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
        "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
        "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
        "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
        "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
        "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
        "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
        "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
        "\n",
        "]\n",
        "\n",
        "# Split into English and French\n",
        "english_sentences, french_sentences = zip(*english_to_french)\n",
        "\n",
        "# Add <SOS> and <EOS> tokens to French sentences\n",
        "french_sentences = ['<SOS> ' + sent + ' <EOS>' for sent in french_sentences]\n",
        "\n",
        "# Tokenization\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(english_sentences)\n",
        "eng_sequences = eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "fr_tokenizer = Tokenizer(filters='')\n",
        "fr_tokenizer.fit_on_texts(french_sentences)\n",
        "\n",
        "# Manually ensure <SOS> and <EOS> are in the vocabulary\n",
        "if '<SOS>' not in fr_tokenizer.word_index:\n",
        "    fr_tokenizer.word_index['<SOS>'] = len(fr_tokenizer.word_index) + 1\n",
        "if '<EOS>' not in fr_tokenizer.word_index:\n",
        "    fr_tokenizer.word_index['<EOS>'] = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(french_sentences)\n",
        "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "# Debug: Inspect the vocabulary\n",
        "print(\"French tokenizer word_index:\", fr_tokenizer.word_index)\n",
        "\n",
        "# Padding sequences\n",
        "max_eng_len = max(len(seq) for seq in eng_sequences)\n",
        "max_fr_len = max(len(seq) for seq in fr_sequences)\n",
        "eng_padded = pad_sequences(eng_sequences, maxlen=max_eng_len, padding='post')\n",
        "fr_padded = pad_sequences(fr_sequences, maxlen=max_fr_len, padding='post')\n",
        "\n",
        "# Prepare decoder input and target data\n",
        "decoder_input_data = fr_padded[:, :-1]  # Exclude <EOS>\n",
        "decoder_target_data = fr_padded[:, 1:]  # Exclude <SOS>\n",
        "\n",
        "# Model Parameters\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_eng_len,))\n",
        "enc_embedding = Embedding(eng_vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_gru = GRU(units, return_state=True)\n",
        "encoder_outputs, encoder_state = encoder_gru(enc_embedding)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(max_fr_len - 1,))\n",
        "dec_embedding = Embedding(fr_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_gru = GRU(units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder_gru(dec_embedding, initial_state=encoder_state)\n",
        "decoder_dense = Dense(fr_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train and evaluate on the entire dataset\n",
        "history = model.fit(\n",
        "    [eng_padded, decoder_input_data],\n",
        "    np.expand_dims(decoder_target_data, -1),\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    validation_data=([eng_padded, decoder_input_data], np.expand_dims(decoder_target_data, -1)),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Report results\n",
        "print(\"Training Loss:\", history.history['loss'][-1])\n",
        "print(\"Validation Loss (Entire Dataset):\", history.history['val_loss'][-1])\n",
        "print(\"Validation Accuracy (Entire Dataset):\", history.history['val_accuracy'][-1])\n",
        "\n",
        "# Inference Setup\n",
        "encoder_model = Model(encoder_inputs, encoder_state)\n",
        "\n",
        "decoder_state_input = Input(shape=(units,))\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "dec_embedding_single = Embedding(fr_vocab_size, embedding_dim)(decoder_inputs_single)\n",
        "decoder_outputs, decoder_state = decoder_gru(dec_embedding_single, initial_state=decoder_state_input)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs_single, decoder_state_input], [decoder_outputs, decoder_state])\n",
        "\n",
        "# Translation Function (improved to stop at first <EOS>)\n",
        "def translate(sentence):\n",
        "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
        "    seq = pad_sequences(seq, maxlen=max_eng_len, padding='post')\n",
        "    state = encoder_model.predict(seq, verbose=0)\n",
        "\n",
        "    # Use <SOS> as defined in the vocabulary\n",
        "    target_seq = np.array([[fr_tokenizer.word_index['<SOS>']]])\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_fr_len):\n",
        "        output_tokens, state = decoder_model.predict([target_seq, state], verbose=0)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
        "        sampled_word = fr_tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        if sampled_word == '<EOS>':\n",
        "            break\n",
        "        if sampled_word:\n",
        "            output_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return ' '.join(output_sentence)\n",
        "\n",
        "# Qualitative Validation\n",
        "test_sentences = [\n",
        "    \"I am cold\",\n",
        "    \"She is happy\",\n",
        "    \"We love music\",\n",
        "    \"He drives a blue car\",\n",
        "    \"The sun is shining\"\n",
        "]\n",
        "\n",
        "print(\"\\nQualitative Validation:\")\n",
        "for sent in test_sentences:\n",
        "    translation = translate(sent)\n",
        "    print(f\"English: {sent} -> French: {translation}\")\n",
        "\n",
        "# Reset eager execution (optional)\n",
        "tf.config.run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Ensure eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Dataset\n",
        "english_to_french = [\n",
        "   (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
        "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
        "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
        "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
        "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
        "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
        "    (\"They go shopping\", \"Ils font du shopping\"),\n",
        "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
        "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
        "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
        "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
        "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
        "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
        "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
        "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
        "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
        "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
        "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
        "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
        "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
        "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
        "    (\"They set the table\", \"Ils mettent la table\"),\n",
        "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
        "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
        "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
        "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
        "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
        "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
        "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
        "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
        "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
        "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
        "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
        "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
        "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
        "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
        "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
        "\n",
        "]\n",
        "\n",
        "####split into English and French\n",
        "english_sentences, french_sentences = zip(*english_to_french)\n",
        "\n",
        "###Add SOS and EOS tokens to French sentences\n",
        "french_sentences = ['<SOS> ' + sent + ' <EOS>' for sent in french_sentences]\n",
        "\n",
        "# Tokenization\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(english_sentences)\n",
        "eng_sequences = eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "fr_tokenizer = Tokenizer(filters='')\n",
        "fr_tokenizer.fit_on_texts(french_sentences)\n",
        "\n",
        "####Ensure <SOS> and <EOS> are in the vocabulary\n",
        "if '<SOS>' not in fr_tokenizer.word_index:\n",
        "    fr_tokenizer.word_index['<SOS>'] = len(fr_tokenizer.word_index) + 1\n",
        "if '<EOS>' not in fr_tokenizer.word_index:\n",
        "    fr_tokenizer.word_index['<EOS>'] = len(fr_tokenizer.word_index) + 1\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(french_sentences)\n",
        "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "#Debug: Inspect the vocabulary\n",
        "print(\"French tokenizer word_index:\", fr_tokenizer.word_index)\n",
        "\n",
        "######Padding sequences\n",
        "max_eng_len = max(len(seq) for seq in eng_sequences)\n",
        "max_fr_len = max(len(seq) for seq in fr_sequences)\n",
        "eng_padded = pad_sequences(eng_sequences, maxlen=max_eng_len, padding='post')\n",
        "fr_padded = pad_sequences(fr_sequences, maxlen=max_fr_len, padding='post')\n",
        "\n",
        "####Prepare decoder input and target data\n",
        "decoder_input_data = fr_padded[:, :-1]  # Exclude <EOS>\n",
        "decoder_target_data = fr_padded[:, 1:]  # Exclude <SOS>\n",
        "\n",
        "####Model Parameters\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(max_eng_len,))\n",
        "enc_embedding = Embedding(eng_vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_gru = GRU(units, return_state=True)\n",
        "encoder_outputs, encoder_state = encoder_gru(enc_embedding)\n",
        "\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(max_fr_len - 1,))\n",
        "dec_embedding = Embedding(fr_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_gru = GRU(units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder_gru(dec_embedding, initial_state=encoder_state)\n",
        "decoder_dense = Dense(fr_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "##################Train and evaluate on the entire dataset\n",
        "history = model.fit(\n",
        "    [eng_padded, decoder_input_data],\n",
        "    np.expand_dims(decoder_target_data, -1),\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    validation_data=([eng_padded, decoder_input_data], np.expand_dims(decoder_target_data, -1)),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#######Report results\n",
        "print(\"Training Loss:\", history.history['loss'][-1])\n",
        "print(\"Validation Loss (Entire Dataset):\", history.history['val_loss'][-1])\n",
        "print(\"Validation Accuracy (Entire Dataset):\", history.history['val_accuracy'][-1])\n",
        "\n",
        "#####Inference Setup\n",
        "encoder_model = Model(encoder_inputs, encoder_state)\n",
        "\n",
        "decoder_state_input = Input(shape=(units,))\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "dec_embedding_single = Embedding(fr_vocab_size, embedding_dim)(decoder_inputs_single)\n",
        "decoder_outputs, decoder_state = decoder_gru(dec_embedding_single, initial_state=decoder_state_input)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs_single, decoder_state_input], [decoder_outputs, decoder_state])\n",
        "\n",
        "#3####Translation Function (fixed to stop at first <EOS> and debug)\n",
        "def translate(sentence):\n",
        "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
        "    seq = pad_sequences(seq, maxlen=max_eng_len, padding='post')\n",
        "    state = encoder_model.predict(seq, verbose=0)\n",
        "\n",
        "    target_seq = np.array([[fr_tokenizer.word_index['<SOS>']]])\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_fr_len):\n",
        "        output_tokens, state = decoder_model.predict([target_seq, state], verbose=0)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
        "        sampled_word = fr_tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        if sampled_word == '<EOS>' or sampled_word == '':\n",
        "            break\n",
        "        output_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return ' '.join(output_sentence)\n",
        "\n",
        "#####Qualitative Validation\n",
        "test_sentences = [\n",
        "    \"I am cold\",\n",
        "    \"She is happy\",\n",
        "    \"We love music\",\n",
        "    \"He drives a blue car\",\n",
        "    \"The sun is shining\"\n",
        "]\n",
        "\n",
        "print(\"\\nQualitative Validation:\")\n",
        "for sent in test_sentences:\n",
        "    translation = translate(sent)\n",
        "    print(f\"English: {sent} -> French: {translation}\")\n",
        "\n",
        "tf.config.run_functions_eagerly(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsLA7wEeTORO",
        "outputId": "5f2d796e-6772-48a6-c71a-8805e0d9086e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French tokenizer word_index: {'<sos>': 1, '<eos>': 2, 'le': 3, 'la': 4, 'il': 5, 'elle': 6, 'nous': 7, 'ils': 8, 'les': 9, 'de': 10, 'à': 11, 'des': 12, 'au': 13, 'dans': 14, 'du': 15, 'une': 16, 'un': 17, 'se': 18, 'font': 19, 'est': 20, 'chat': 21, 'dort': 22, 'soleil': 23, 'musique': 24, 'jouent': 25, 'porte': 26, 'ensemble': 27, 'étudie': 28, 'bruyamment': 29, 'chante': 30, 'matin': 31, 'pour': 32, 'brille': 33, 'livres': 34, 'chaque': 35, 'film': 36, 'dîner': 37, 'voiture': 38, 'visitent': 39, 'cuisine': 40, 'regardons': 41, 'en': 42, 'voyagent': 43, 'table': 44, 'danse': 45, 'avec': 46, 'dur': 47, 'fleurs': 48, 'écrit': 49, 'son': 50, 'peint': 51, 'parc': 52, 'train': 53, 'bébé': 54, 'répare': 55, 'café': 56, 'doucement': 57, 'bus': 58, 'vélo': 59, 'nos': 60, 'ses': 61, \"j'ai\": 62, 'froid': 63, 'tu': 64, 'es': 65, 'fatigué': 66, 'a': 67, 'faim': 68, 'heureuse': 69, 'sommes': 70, 'amis': 71, 'sont': 72, 'étudiants': 73, 'aimons': 74, 'parle': 75, 'français': 76, 'couramment': 77, 'aime': 78, 'lire': 79, 'football': 80, 'week-end': 81, 'commence': 82, '19': 83, 'heures': 84, 'robe': 85, 'rouge': 86, 'cuisinons': 87, 'conduit': 88, 'bleue': 89, 'souvent': 90, 'musées': 91, 'restaurant': 92, 'sert': 93, 'délicieuse': 94, 'mathématiques': 95, \"l'université\": 96, 'films': 97, 'vendredi': 98, 'écoute': 99, 'faisant': 100, 'jogging': 101, 'autour': 102, 'monde': 103, 'livre': 104, 'sur': 105, 'grâce': 106, 'célébrons': 107, 'anniversaires': 108, 'gâteau': 109, 'travaille': 110, 'tous': 111, 'jours': 112, 'parlent': 113, 'différentes': 114, 'langues': 115, 'fleurissent': 116, 'printemps': 117, 'poésie': 118, 'pendant': 119, 'temps': 120, 'libre': 121, 'apprenons': 122, 'quelque': 123, 'chose': 124, 'nouveau': 125, 'jour': 126, 'chien': 127, 'aboie': 128, 'magnifiquement': 129, 'nagent': 130, 'piscine': 131, 'oiseaux': 132, 'gazouillent': 133, 'enseigne': 134, \"l'anglais\": 135, \"l'école\": 136, 'prenons': 137, 'petit': 138, 'déjeuner': 139, 'paysages': 140, 'rient': 141, 'blague': 142, \"l'horloge\": 143, 'tic-tac': 144, 'court': 145, 'voyageons': 146, 'lettre': 147, 'lisent': 148, 'bibliothèque': 149, 'pleure': 150, 'examens': 151, 'plantons': 152, 'jardin': 153, 'boivent': 154, 'couche': 155, 'soir': 156, 'fête': 157, 'jouons': 158, 'concert': 159, 'sa': 160, 'famille': 161, 'étudient': 162, 'grammaire': 163, 'française': 164, 'pluie': 165, 'tombe': 166, 'chanson': 167, 'profondément': 168, 'paris': 169, 'enfants': 170, 'promène': 171, 'long': 172, 'plage': 173, 'parlons': 174, 'téléphone': 175, 'attend': 176, 'tour': 177, 'eiffel': 178, 'étoiles': 179, 'scintillent': 180, 'nuit': 181, 'rêve': 182, 'voler': 183, 'travaillons': 184, 'bureau': 185, \"l'histoire\": 186, 'écoutent': 187, 'radio': 188, 'vent': 189, 'souffle': 190, 'nage': 191, \"l'océan\": 192, 'dansons': 193, 'mariage': 194, 'gravit': 195, 'montagne': 196, 'randonnée': 197, 'forêt': 198, 'miaule': 199, 'tableau': 200, 'construisons': 201, 'château': 202, 'sable': 203, 'chœur': 204, 'chaud': 205, 'lunettes': 206, 'rendons': 207, 'visite': 208, 'grands-parents': 209, 'joue': 210, 'guitare': 211, 'shopping': 212, 'professeur': 213, 'explique': 214, 'leçon': 215, 'prend': 216, 'aller': 217, 'travail': 218, 'faisons': 219, 'biscuits': 220, 'lave': 221, 'mains': 222, 'apprécient': 223, 'coucher': 224, 'rivière': 225, 'coule': 226, 'calmement': 227, 'nourrit': 228, 'visitons': 229, 'musée': 230, 'peignent': 231, 'murs': 232, 'paisiblement': 233, 'attache': 234, 'lacets': 235, 'montons': 236, 'escaliers': 237, 'rase': 238, 'mettent': 239, \"l'avion\": 240, 'décolle': 241, 'arrose': 242, 'plantes': 243, 'pratiquons': 244, 'yoga': 245, 'éteint': 246, 'lumière': 247, 'aux': 248, 'jeux': 249, 'vidéo': 250, 'soupe': 251, 'sent': 252, 'délicieusement': 253, 'bon': 254, 'ferme': 255, 'clé': 256, 'profitons': 257, \"d'un\": 258, 'pique-nique': 259, 'vérifie': 260, 'emails': 261, 'vont': 262, 'salle': 263, 'sport': 264, 'lune': 265, 'intensément': 266, 'attrape': 267, 'saluons': 268, 'voisins': 269, 'peigne': 270, 'cheveux': 271, 'signe': 272, \"d'adieu\": 273, '<SOS>': 274, '<EOS>': 275}\n",
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.2319 - loss: 5.5432 - val_accuracy: 0.4434 - val_loss: 5.0273\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.4411 - loss: 4.6183 - val_accuracy: 0.4239 - val_loss: 3.6985\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 960ms/step - accuracy: 0.4287 - loss: 3.4663 - val_accuracy: 0.4434 - val_loss: 3.1484\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.4513 - loss: 3.1144 - val_accuracy: 0.4434 - val_loss: 3.0062\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 960ms/step - accuracy: 0.4520 - loss: 2.9011 - val_accuracy: 0.4522 - val_loss: 2.6837\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 962ms/step - accuracy: 0.4907 - loss: 2.6804 - val_accuracy: 0.5425 - val_loss: 2.6803\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5500 - loss: 2.5752 - val_accuracy: 0.5425 - val_loss: 2.5094\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 980ms/step - accuracy: 0.5547 - loss: 2.4692 - val_accuracy: 0.5540 - val_loss: 2.4706\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 814ms/step - accuracy: 0.5431 - loss: 2.4987 - val_accuracy: 0.5496 - val_loss: 2.3946\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.5476 - loss: 2.3515 - val_accuracy: 0.5434 - val_loss: 2.3392\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 954ms/step - accuracy: 0.5521 - loss: 2.2788 - val_accuracy: 0.5522 - val_loss: 2.2875\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 825ms/step - accuracy: 0.5547 - loss: 2.2639 - val_accuracy: 0.5504 - val_loss: 2.2337\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5614 - loss: 2.1937 - val_accuracy: 0.5584 - val_loss: 2.1916\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 951ms/step - accuracy: 0.5489 - loss: 2.1645 - val_accuracy: 0.5655 - val_loss: 2.1453\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 799ms/step - accuracy: 0.5600 - loss: 2.1381 - val_accuracy: 0.5584 - val_loss: 2.0996\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 960ms/step - accuracy: 0.5624 - loss: 2.0655 - val_accuracy: 0.5593 - val_loss: 2.0620\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 955ms/step - accuracy: 0.5552 - loss: 2.0871 - val_accuracy: 0.5628 - val_loss: 2.0189\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 967ms/step - accuracy: 0.5579 - loss: 2.0472 - val_accuracy: 0.5814 - val_loss: 1.9729\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.5814 - loss: 1.9595 - val_accuracy: 0.5752 - val_loss: 1.9283\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5829 - loss: 1.8986 - val_accuracy: 0.5912 - val_loss: 1.9049\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5946 - loss: 1.8479 - val_accuracy: 0.6071 - val_loss: 1.8631\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5977 - loss: 1.8615 - val_accuracy: 0.5920 - val_loss: 1.8106\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 963ms/step - accuracy: 0.5979 - loss: 1.8003 - val_accuracy: 0.6027 - val_loss: 1.7499\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 986ms/step - accuracy: 0.5999 - loss: 1.7610 - val_accuracy: 0.6230 - val_loss: 1.7102\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 980ms/step - accuracy: 0.6229 - loss: 1.7166 - val_accuracy: 0.6283 - val_loss: 1.6521\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 964ms/step - accuracy: 0.6230 - loss: 1.6634 - val_accuracy: 0.6319 - val_loss: 1.5879\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.6290 - loss: 1.5987 - val_accuracy: 0.6363 - val_loss: 1.5220\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 981ms/step - accuracy: 0.6444 - loss: 1.5234 - val_accuracy: 0.6575 - val_loss: 1.4600\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 967ms/step - accuracy: 0.6602 - loss: 1.4357 - val_accuracy: 0.6664 - val_loss: 1.3938\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.6638 - loss: 1.3905 - val_accuracy: 0.6708 - val_loss: 1.3297\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 954ms/step - accuracy: 0.6769 - loss: 1.3052 - val_accuracy: 0.6947 - val_loss: 1.2592\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.6862 - loss: 1.2666 - val_accuracy: 0.7000 - val_loss: 1.1905\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 960ms/step - accuracy: 0.7095 - loss: 1.1321 - val_accuracy: 0.7177 - val_loss: 1.1186\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 960ms/step - accuracy: 0.7154 - loss: 1.1415 - val_accuracy: 0.7469 - val_loss: 1.0480\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7561 - loss: 1.0159 - val_accuracy: 0.7628 - val_loss: 0.9838\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 967ms/step - accuracy: 0.7637 - loss: 0.9621 - val_accuracy: 0.7850 - val_loss: 0.9173\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 972ms/step - accuracy: 0.7829 - loss: 0.9155 - val_accuracy: 0.7956 - val_loss: 0.8606\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 946ms/step - accuracy: 0.7929 - loss: 0.8651 - val_accuracy: 0.8035 - val_loss: 0.8056\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 962ms/step - accuracy: 0.7959 - loss: 0.7990 - val_accuracy: 0.8327 - val_loss: 0.7388\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.8216 - loss: 0.7469 - val_accuracy: 0.8478 - val_loss: 0.6949\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 975ms/step - accuracy: 0.8356 - loss: 0.6856 - val_accuracy: 0.8549 - val_loss: 0.6512\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 947ms/step - accuracy: 0.8469 - loss: 0.6456 - val_accuracy: 0.8531 - val_loss: 0.6304\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 952ms/step - accuracy: 0.8584 - loss: 0.6260 - val_accuracy: 0.8876 - val_loss: 0.5579\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 954ms/step - accuracy: 0.8800 - loss: 0.5714 - val_accuracy: 0.8947 - val_loss: 0.5223\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8808 - loss: 0.5350 - val_accuracy: 0.8982 - val_loss: 0.4938\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 947ms/step - accuracy: 0.8957 - loss: 0.4965 - val_accuracy: 0.8973 - val_loss: 0.4650\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 961ms/step - accuracy: 0.8978 - loss: 0.4571 - val_accuracy: 0.9044 - val_loss: 0.4415\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8990 - loss: 0.4433 - val_accuracy: 0.9044 - val_loss: 0.4146\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 967ms/step - accuracy: 0.9067 - loss: 0.4114 - val_accuracy: 0.9150 - val_loss: 0.3861\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 969ms/step - accuracy: 0.9124 - loss: 0.3878 - val_accuracy: 0.9159 - val_loss: 0.3675\n",
            "Training Loss: 0.3815925419330597\n",
            "Validation Loss (Entire Dataset): 0.367500901222229\n",
            "Validation Accuracy (Entire Dataset): 0.9159291386604309\n",
            "\n",
            "Qualitative Validation:\n",
            "English: I am cold -> French: j'ai froid <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: She is happy -> French: elle dort <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: We love music -> French: nous froid amis <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: He drives a blue car -> French: il se une <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: The sun is shining -> French: le dort <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
          ]
        }
      ]
    }
  ]
}