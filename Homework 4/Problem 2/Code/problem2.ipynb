{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Attention, Lambda\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Dataset full list\n",
        "english_to_french = [\n",
        "    (\"I am cold\", \"J'ai froid\"),\n",
        "    (\"You are tired\", \"Tu es fatigué\"),\n",
        "    (\"He is hungry\", \"Il a faim\"),\n",
        "    (\"She is happy\", \"Elle est heureuse\"),\n",
        "    (\"We are friends\", \"Nous sommes amis\"),\n",
        "    (\"They are students\", \"Ils sont étudiants\"),\n",
        "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
        "    (\"The sun is shining\", \"Le soleil brille\"),\n",
        "    (\"We love music\", \"Nous aimons la musique\"),\n",
        "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
        "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
        "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
        "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
        "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
        "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
        "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
        "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
        "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
        "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
        "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
        "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
        "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
        "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
        "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
        "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
        "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
        "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
        "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
        "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
        "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
        "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
        "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
        "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
        "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
        "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
        "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
        "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
        "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
        "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
        "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
        "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
        "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
        "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
        "    (\"The baby cries\", \"Le bébé pleure\"),\n",
        "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
        "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
        "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
        "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
        "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
        "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
        "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
        "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
        "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
        "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
        "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
        "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
        "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
        "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
        "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
        "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
        "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
        "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
        "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
        "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
        "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
        "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
        "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
        "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
        "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
        "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
        "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
        "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
        "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
        "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
        "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
        "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
        "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
        "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
        "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
        "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
        "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
        "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
        "    (\"They go shopping\", \"Ils font du shopping\"),\n",
        "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
        "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
        "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
        "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
        "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
        "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
        "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
        "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
        "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
        "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
        "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
        "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
        "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
        "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
        "    (\"They set the table\", \"Ils mettent la table\"),\n",
        "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
        "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
        "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
        "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
        "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
        "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
        "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
        "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
        "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
        "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
        "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
        "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
        "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
        "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
        "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
        "]\n",
        "\n",
        "# Split into English and French\n",
        "english_sentences, french_sentences = zip(*english_to_french)\n",
        "\n",
        "french_sentences = ['<SOS> ' + sent + ' <EOS>' for sent in french_sentences]\n",
        "\n",
        "####Tokenization\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(english_sentences)\n",
        "eng_sequences = eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "fr_tokenizer = Tokenizer(filters='')\n",
        "fr_tokenizer.fit_on_texts(french_sentences)\n",
        "if '<SOS>' not in fr_tokenizer.word_index:\n",
        "    fr_tokenizer.word_index['<SOS>'] = len(fr_tokenizer.word_index) + 1\n",
        "if '<EOS>' not in fr_tokenizer.word_index:\n",
        "    fr_tokenizer.word_index['<EOS>'] = len(fr_tokenizer.word_index) + 1\n",
        "fr_sequences = fr_tokenizer.texts_to_sequences(french_sentences)\n",
        "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "##Debug: Inspect the vocabulary\n",
        "print(\"French tokenizer word_index:\", fr_tokenizer.word_index)\n",
        "\n",
        "######Padding sequences\n",
        "max_eng_len = max(len(seq) for seq in eng_sequences)\n",
        "max_fr_len = max(len(seq) for seq in fr_sequences)\n",
        "eng_padded = pad_sequences(eng_sequences, maxlen=max_eng_len, padding='post')\n",
        "fr_padded = pad_sequences(fr_sequences, maxlen=max_fr_len, padding='post')\n",
        "\n",
        "#########Prepare decoder input and target data\n",
        "decoder_input_data = fr_padded[:, :-1]  # Exclude <EOS>\n",
        "decoder_target_data = fr_padded[:, 1:]  # Exclude <SOS>\n",
        "\n",
        "######Model Parameters\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "\n",
        "#####Encoder\n",
        "encoder_inputs = Input(shape=(max_eng_len,))\n",
        "enc_embedding = Embedding(eng_vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_gru = GRU(units, return_sequences=True, return_state=True)  # Return sequences for attention\n",
        "encoder_outputs, encoder_state = encoder_gru(enc_embedding)\n",
        "\n",
        "####Decoder\n",
        "decoder_inputs = Input(shape=(max_fr_len - 1,))\n",
        "dec_embedding = Embedding(fr_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_gru = GRU(units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder_gru(dec_embedding, initial_state=encoder_state)\n",
        "\n",
        "###############################Attention Layer#############################\n",
        "attention = Attention()\n",
        "context = attention([decoder_outputs, encoder_outputs])  # [query, value]\n",
        "\n",
        "#Combine GRU output and context using Lambda layer\n",
        "decoder_combined_context = Lambda(lambda x: tf.concat(x, axis=-1))([decoder_outputs, context])\n",
        "\n",
        "# Dense Output Layer\n",
        "decoder_dense = Dense(fr_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train and evaluate on the entire dataset\n",
        "history = model.fit(\n",
        "    [eng_padded, decoder_input_data],\n",
        "    np.expand_dims(decoder_target_data, -1),\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    validation_data=([eng_padded, decoder_input_data], np.expand_dims(decoder_target_data, -1)),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Report results\n",
        "print(\"Training Loss:\", history.history['loss'][-1])\n",
        "print(\"Validation Loss (Entire Dataset):\", history.history['val_loss'][-1])\n",
        "print(\"Validation Accuracy (Entire Dataset):\", history.history['val_accuracy'][-1])\n",
        "\n",
        "# Inference Setup\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_state])\n",
        "\n",
        "decoder_state_input = Input(shape=(units,))\n",
        "decoder_outputs_input = Input(shape=(None, units))  # For attention\n",
        "encoder_outputs_input = Input(shape=(None, units))\n",
        "dec_embedding_single = Embedding(fr_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_outputs_single, decoder_state = decoder_gru(dec_embedding_single, initial_state=decoder_state_input)\n",
        "context_single = attention([decoder_outputs_single, encoder_outputs_input])\n",
        "decoder_combined_context_single = Lambda(lambda x: tf.concat(x, axis=-1))([decoder_outputs_single, context_single])\n",
        "decoder_outputs_single = decoder_dense(decoder_combined_context_single)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs, decoder_state_input, encoder_outputs_input],\n",
        "    [decoder_outputs_single, decoder_state]\n",
        ")\n",
        "\n",
        "####Translation Function\n",
        "def translate(sentence):\n",
        "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
        "    seq = pad_sequences(seq, maxlen=max_eng_len, padding='post')\n",
        "    enc_outputs, state = encoder_model.predict(seq, verbose=0)\n",
        "\n",
        "    target_seq = np.array([[fr_tokenizer.word_index['<SOS>']]])\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_fr_len):\n",
        "        output_tokens, state = decoder_model.predict([target_seq, state, enc_outputs], verbose=0)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = fr_tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        if sampled_word == '<EOS>' or sampled_word == '':\n",
        "            break\n",
        "        output_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return ' '.join(output_sentence)\n",
        "\n",
        "#####Qualitative Validation\n",
        "test_sentences = [\n",
        "    \"I am cold\",\n",
        "    \"She is happy\",\n",
        "    \"We love music\",\n",
        "    \"He drives a blue car\",\n",
        "    \"The sun is shining\"\n",
        "]\n",
        "\n",
        "print(\"\\nQualitative Validation:\")\n",
        "for sent in test_sentences:\n",
        "    translation = translate(sent)\n",
        "    print(f\"English: {sent} -> French: {translation}\")\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4v5c52sdPJN",
        "outputId": "bb5b2aae-219f-46c3-960c-5b1c346c83fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French tokenizer word_index: {'<sos>': 1, '<eos>': 2, 'le': 3, 'la': 4, 'il': 5, 'elle': 6, 'nous': 7, 'ils': 8, 'les': 9, 'de': 10, 'à': 11, 'des': 12, 'au': 13, 'dans': 14, 'du': 15, 'une': 16, 'un': 17, 'se': 18, 'font': 19, 'est': 20, 'chat': 21, 'dort': 22, 'soleil': 23, 'musique': 24, 'jouent': 25, 'porte': 26, 'ensemble': 27, 'étudie': 28, 'bruyamment': 29, 'chante': 30, 'matin': 31, 'pour': 32, 'brille': 33, 'livres': 34, 'chaque': 35, 'film': 36, 'dîner': 37, 'voiture': 38, 'visitent': 39, 'cuisine': 40, 'regardons': 41, 'en': 42, 'voyagent': 43, 'table': 44, 'danse': 45, 'avec': 46, 'dur': 47, 'fleurs': 48, 'écrit': 49, 'son': 50, 'peint': 51, 'parc': 52, 'train': 53, 'bébé': 54, 'répare': 55, 'café': 56, 'doucement': 57, 'bus': 58, 'vélo': 59, 'nos': 60, 'ses': 61, \"j'ai\": 62, 'froid': 63, 'tu': 64, 'es': 65, 'fatigué': 66, 'a': 67, 'faim': 68, 'heureuse': 69, 'sommes': 70, 'amis': 71, 'sont': 72, 'étudiants': 73, 'aimons': 74, 'parle': 75, 'français': 76, 'couramment': 77, 'aime': 78, 'lire': 79, 'football': 80, 'week-end': 81, 'commence': 82, '19': 83, 'heures': 84, 'robe': 85, 'rouge': 86, 'cuisinons': 87, 'conduit': 88, 'bleue': 89, 'souvent': 90, 'musées': 91, 'restaurant': 92, 'sert': 93, 'délicieuse': 94, 'mathématiques': 95, \"l'université\": 96, 'films': 97, 'vendredi': 98, 'écoute': 99, 'faisant': 100, 'jogging': 101, 'autour': 102, 'monde': 103, 'livre': 104, 'sur': 105, 'grâce': 106, 'célébrons': 107, 'anniversaires': 108, 'gâteau': 109, 'travaille': 110, 'tous': 111, 'jours': 112, 'parlent': 113, 'différentes': 114, 'langues': 115, 'fleurissent': 116, 'printemps': 117, 'poésie': 118, 'pendant': 119, 'temps': 120, 'libre': 121, 'apprenons': 122, 'quelque': 123, 'chose': 124, 'nouveau': 125, 'jour': 126, 'chien': 127, 'aboie': 128, 'magnifiquement': 129, 'nagent': 130, 'piscine': 131, 'oiseaux': 132, 'gazouillent': 133, 'enseigne': 134, \"l'anglais\": 135, \"l'école\": 136, 'prenons': 137, 'petit': 138, 'déjeuner': 139, 'paysages': 140, 'rient': 141, 'blague': 142, \"l'horloge\": 143, 'tic-tac': 144, 'court': 145, 'voyageons': 146, 'lettre': 147, 'lisent': 148, 'bibliothèque': 149, 'pleure': 150, 'examens': 151, 'plantons': 152, 'jardin': 153, 'boivent': 154, 'couche': 155, 'soir': 156, 'fête': 157, 'jouons': 158, 'concert': 159, 'sa': 160, 'famille': 161, 'étudient': 162, 'grammaire': 163, 'française': 164, 'pluie': 165, 'tombe': 166, 'chanson': 167, 'profondément': 168, 'paris': 169, 'enfants': 170, 'promène': 171, 'long': 172, 'plage': 173, 'parlons': 174, 'téléphone': 175, 'attend': 176, 'tour': 177, 'eiffel': 178, 'étoiles': 179, 'scintillent': 180, 'nuit': 181, 'rêve': 182, 'voler': 183, 'travaillons': 184, 'bureau': 185, \"l'histoire\": 186, 'écoutent': 187, 'radio': 188, 'vent': 189, 'souffle': 190, 'nage': 191, \"l'océan\": 192, 'dansons': 193, 'mariage': 194, 'gravit': 195, 'montagne': 196, 'randonnée': 197, 'forêt': 198, 'miaule': 199, 'tableau': 200, 'construisons': 201, 'château': 202, 'sable': 203, 'chœur': 204, 'chaud': 205, 'lunettes': 206, 'rendons': 207, 'visite': 208, 'grands-parents': 209, 'joue': 210, 'guitare': 211, 'shopping': 212, 'professeur': 213, 'explique': 214, 'leçon': 215, 'prend': 216, 'aller': 217, 'travail': 218, 'faisons': 219, 'biscuits': 220, 'lave': 221, 'mains': 222, 'apprécient': 223, 'coucher': 224, 'rivière': 225, 'coule': 226, 'calmement': 227, 'nourrit': 228, 'visitons': 229, 'musée': 230, 'peignent': 231, 'murs': 232, 'paisiblement': 233, 'attache': 234, 'lacets': 235, 'montons': 236, 'escaliers': 237, 'rase': 238, 'mettent': 239, \"l'avion\": 240, 'décolle': 241, 'arrose': 242, 'plantes': 243, 'pratiquons': 244, 'yoga': 245, 'éteint': 246, 'lumière': 247, 'aux': 248, 'jeux': 249, 'vidéo': 250, 'soupe': 251, 'sent': 252, 'délicieusement': 253, 'bon': 254, 'ferme': 255, 'clé': 256, 'profitons': 257, \"d'un\": 258, 'pique-nique': 259, 'vérifie': 260, 'emails': 261, 'vont': 262, 'salle': 263, 'sport': 264, 'lune': 265, 'intensément': 266, 'attrape': 267, 'saluons': 268, 'voisins': 269, 'peigne': 270, 'cheveux': 271, 'signe': 272, \"d'adieu\": 273, '<SOS>': 274, '<EOS>': 275}\n",
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.2247 - loss: 5.5211 - val_accuracy: 0.4239 - val_loss: 4.8667\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 987ms/step - accuracy: 0.4207 - loss: 4.4017 - val_accuracy: 0.4239 - val_loss: 3.2859\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.4190 - loss: 3.1692 - val_accuracy: 0.4239 - val_loss: 2.9466\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 986ms/step - accuracy: 0.4195 - loss: 2.9008 - val_accuracy: 0.4345 - val_loss: 2.7263\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.4708 - loss: 2.7415 - val_accuracy: 0.5425 - val_loss: 2.5936\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5447 - loss: 2.5798 - val_accuracy: 0.5434 - val_loss: 2.5486\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 995ms/step - accuracy: 0.5404 - loss: 2.5482 - val_accuracy: 0.5381 - val_loss: 2.4913\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 860ms/step - accuracy: 0.5247 - loss: 2.5557 - val_accuracy: 0.5434 - val_loss: 2.4006\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 992ms/step - accuracy: 0.5568 - loss: 2.3486 - val_accuracy: 0.5442 - val_loss: 2.3286\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.5497 - loss: 2.3051 - val_accuracy: 0.5442 - val_loss: 2.2677\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5590 - loss: 2.2054 - val_accuracy: 0.5504 - val_loss: 2.2094\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5588 - loss: 2.1676 - val_accuracy: 0.5504 - val_loss: 2.1462\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5580 - loss: 2.1215 - val_accuracy: 0.5566 - val_loss: 2.1002\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5599 - loss: 2.0876 - val_accuracy: 0.5681 - val_loss: 2.0514\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5724 - loss: 2.0080 - val_accuracy: 0.5673 - val_loss: 2.0026\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.5617 - loss: 1.9968 - val_accuracy: 0.5664 - val_loss: 1.9511\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 997ms/step - accuracy: 0.5708 - loss: 1.9181 - val_accuracy: 0.5832 - val_loss: 1.8955\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.5894 - loss: 1.9028 - val_accuracy: 0.5779 - val_loss: 1.8626\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5756 - loss: 1.8703 - val_accuracy: 0.5841 - val_loss: 1.8055\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 995ms/step - accuracy: 0.5864 - loss: 1.7667 - val_accuracy: 0.6000 - val_loss: 1.7547\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 996ms/step - accuracy: 0.5957 - loss: 1.7412 - val_accuracy: 0.5920 - val_loss: 1.7093\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.5984 - loss: 1.6954 - val_accuracy: 0.5956 - val_loss: 1.6507\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 995ms/step - accuracy: 0.5939 - loss: 1.6414 - val_accuracy: 0.6080 - val_loss: 1.5994\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 996ms/step - accuracy: 0.6209 - loss: 1.5778 - val_accuracy: 0.6230 - val_loss: 1.5611\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.6165 - loss: 1.5464 - val_accuracy: 0.6425 - val_loss: 1.4834\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.6476 - loss: 1.4895 - val_accuracy: 0.6363 - val_loss: 1.4325\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.6426 - loss: 1.4216 - val_accuracy: 0.6726 - val_loss: 1.3649\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 992ms/step - accuracy: 0.6748 - loss: 1.3591 - val_accuracy: 0.6956 - val_loss: 1.2990\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.6894 - loss: 1.2929 - val_accuracy: 0.7044 - val_loss: 1.2249\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.7013 - loss: 1.2359 - val_accuracy: 0.7434 - val_loss: 1.1308\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.7485 - loss: 1.0977 - val_accuracy: 0.7496 - val_loss: 1.0333\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.7551 - loss: 1.0101 - val_accuracy: 0.7841 - val_loss: 0.9410\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7905 - loss: 0.9378 - val_accuracy: 0.7982 - val_loss: 0.8659\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 853ms/step - accuracy: 0.7938 - loss: 0.8684 - val_accuracy: 0.8053 - val_loss: 0.7965\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 996ms/step - accuracy: 0.8199 - loss: 0.7857 - val_accuracy: 0.8230 - val_loss: 0.7426\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8211 - loss: 0.7460 - val_accuracy: 0.8469 - val_loss: 0.6650\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 991ms/step - accuracy: 0.8441 - loss: 0.6706 - val_accuracy: 0.8593 - val_loss: 0.6309\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8584 - loss: 0.6090 - val_accuracy: 0.8690 - val_loss: 0.5712\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.8696 - loss: 0.5812 - val_accuracy: 0.8761 - val_loss: 0.5272\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8694 - loss: 0.5310 - val_accuracy: 0.8903 - val_loss: 0.4827\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 882ms/step - accuracy: 0.8857 - loss: 0.4866 - val_accuracy: 0.8965 - val_loss: 0.4540\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9007 - loss: 0.4479 - val_accuracy: 0.9106 - val_loss: 0.4139\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9119 - loss: 0.4171 - val_accuracy: 0.9186 - val_loss: 0.3860\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9153 - loss: 0.3813 - val_accuracy: 0.9310 - val_loss: 0.3550\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9200 - loss: 0.3630 - val_accuracy: 0.9336 - val_loss: 0.3282\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 887ms/step - accuracy: 0.9294 - loss: 0.3366 - val_accuracy: 0.9442 - val_loss: 0.3018\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9356 - loss: 0.3064 - val_accuracy: 0.9469 - val_loss: 0.2776\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.9428 - loss: 0.2785 - val_accuracy: 0.9540 - val_loss: 0.2587\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9506 - loss: 0.2600 - val_accuracy: 0.9584 - val_loss: 0.2374\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9596 - loss: 0.2357 - val_accuracy: 0.9611 - val_loss: 0.2198\n",
            "Training Loss: 0.2399909496307373\n",
            "Validation Loss (Entire Dataset): 0.21975086629390717\n",
            "Validation Accuracy (Entire Dataset): 0.961061954498291\n",
            "\n",
            "Qualitative Validation:\n",
            "English: I am cold -> French: j'ai es fatigué voisins <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: She is happy -> French: elle porte heureuse grâce <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: We love music -> French: nous aimons des pique-nique <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: He drives a blue car -> French: il chante une <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "English: The sun is shining -> French: le se dans le <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
          ]
        }
      ]
    }
  ]
}